{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer:\n",
    "    def __init__(self,weight, bias) :\n",
    "        self.weight = weight\n",
    "        self.bias = bias\n",
    "        \n",
    "    def activation(self,input, func) :\n",
    "        return func(input)\n",
    "\n",
    "    def forward(self, input, func) :\n",
    "        output = torch.matmul(input,self.weight)\n",
    "        if (self.bias is not None):\n",
    "            output += self.bias\n",
    "        return self.activation(output, func)\n",
    "    \n",
    "    def evaluate(self, pred, target) : #MSE\n",
    "        return nn.MSELoss()(pred,target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network:\n",
    "    def __init__ (self, batchSize, weights, biases, totalLayer, forwards, learningRate, epoch):\n",
    "        self.batchSize = batchSize #ukuran batch\n",
    "        self.learningRate = learningRate\n",
    "        self.epoch = epoch\n",
    "        self.totalLayer = totalLayer #total layer yang digunakan\n",
    "        self.forwards = forwards #buat nentuin pake forward function apa aja pada setiap layer\n",
    "        self.layers = [] #list of layers\n",
    "        self.functions = [self.reLU, self.sigmoid, self.tanh, self.softmax] #list of function, kalo di layer 1 mau pake sigmoid, maka di self.functions[0] = 1\n",
    "        for i in range (0, totalLayer):\n",
    "            self.layers.append(Layer(weights[i], biases[i])) #layer ke i disimpan dalam self.layers[i]\n",
    "    \n",
    "    def forward (self, input):\n",
    "        for i in range (0, self.totalLayer):\n",
    "          input = self.layers[i].forward(input, self.functions[self.forwards[i]])\n",
    "        return input\n",
    "\n",
    "    def backward (self, loss):\n",
    "        loss.backward()\n",
    "        for i in range (0, self.totalLayer):\n",
    "            with torch.no_grad():\n",
    "                self.layers[i].weight += self.learningRate * self.layers[i].weight.grad\n",
    "            self.layers[i].weight.grad.zero_()\n",
    "    \n",
    "    def singleProcessing (self, input, target):\n",
    "        pred = self.forward(input)\n",
    "        loss = self.evaluate(pred, target)\n",
    "        self.backward(loss)\n",
    "\n",
    "    def batchProcessing (self, input, target):\n",
    "        wholeInput = torch.split(input, self.batchSize)\n",
    "        wholeTarget = torch.split(target, self.batchSize)\n",
    "        sz = len(wholeInput)\n",
    "        for i in range (0, sz):\n",
    "            self.singleProcessing(wholeInput[i], wholeTarget[i])\n",
    "\n",
    "    def printLoss (self, input, target):\n",
    "        wholeInput = torch.split(input, self.batchSize)\n",
    "        wholeTarget = torch.split(target, self.batchSize)\n",
    "        sz = len(wholeInput)\n",
    "        for i in range (0, sz):\n",
    "            pred = self.forward(wholeInput[i])\n",
    "            print(self.evaluate(pred, wholeTarget[i]))\n",
    "\n",
    "    def startLearning (self, input, target):\n",
    "        for i in range (0, self.epoch):\n",
    "            self.batchProcessing(input, target)\n",
    "        self.printLoss(input, target)\n",
    "        \n",
    "    def reLU(self, input):\n",
    "        return nn.ReLU()(input)\n",
    "\n",
    "    def sigmoid(self, input):\n",
    "        return nn.Sigmoid()(input)\n",
    "\n",
    "    def tanh(self, input):\n",
    "        return nn.Tanh()(input)\n",
    "\n",
    "    def softmax(self, input):\n",
    "        return nn.Softmax(dim=0)(input)\n",
    "    \n",
    "    def evaluate(self, pred, target):\n",
    "        return nn.MSELoss()(pred,target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.1049, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.6469, grad_fn=<MseLossBackward0>)\n",
      "tensor(2.4009, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.6261, grad_fn=<MseLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# COBA COBA AJA\n",
    "\n",
    "input = torch.Tensor([[-1.1258398,  -1.1523602],\n",
    "                      [-0.25057858, -0.4338788],\n",
    "                      [0.84871036,  0.69200915],\n",
    "                      [-0.31601277, -2.1152194],\n",
    "                      [0.32227492, -1.2633348],\n",
    "                      [0.3499832,  0.30813393],\n",
    "                      [0.11984151,  1.2376579],\n",
    "                      [1.1167772,  -0.24727815],\n",
    "                      [-1.3526537,  -1.6959312],\n",
    "                      [0.5666506,   0.79350835],\n",
    "                      [0.59883946, -1.5550951],\n",
    "                      [-0.3413604,   1.8530061],\n",
    "                      [-0.21586326, -0.74254817],\n",
    "                      [0.5627214,   0.2596274],\n",
    "                      [-0.173961,   -0.6787462],\n",
    "                      [0.93826073,  0.48886982],\n",
    "                      [1.2032237,   0.0845347],\n",
    "                      [-1.2001394,  -0.00478574],\n",
    "                      [-0.5180748,  -0.3067042],\n",
    "                      [-1.5809939,   1.7066433]])\n",
    "\n",
    "target = torch.Tensor([[0.20552567, -0.45032975],\n",
    "                       [-0.5730771,  -0.5553584],\n",
    "                       [0.59432304,  1.5419426],\n",
    "                       [0.5073344,  -0.59103316],\n",
    "                       [-1.325326,    0.18855357],\n",
    "                       [-0.06907269, -0.49492535],\n",
    "                       [-1.4959149,  -0.19383712],\n",
    "                       [0.44551218,  1.3252748],\n",
    "                       [1.5091219,   2.0819554],\n",
    "                       [1.7067116,   2.3803675],\n",
    "                       [-1.1256016, -0.3169981],\n",
    "                       [-1.0924683,  -0.0851943],\n",
    "                       [1.645867,   -1.3601689],\n",
    "                       [0.34456542,  0.5198677],\n",
    "                       [-2.6133225,  -1.6964744],\n",
    "                       [-0.22824179,  0.279955],\n",
    "                       [0.2469264,  0.076887],\n",
    "                       [0.3380058,   0.45440176],\n",
    "                       [0.45694014, -0.86537135],\n",
    "                       [0.78130794, -0.9267894]])\n",
    "\n",
    "weights = [\n",
    "\n",
    "    torch.tensor([[-1.5054897,  -0.66098255,  1.3232017,   0.0371143,  -0.2849093],\n",
    "                 [-0.13344175,  1.8929105,   3.1110442,  -0.4583958,  -0.33598807]], requires_grad = True),\n",
    "\n",
    "    torch.tensor([[-1.7342502,  -1.3360486,   0.88709605],\n",
    "                  [0.76795745,  0.057113,    0.22395839],\n",
    "                  [0.5519643,  -0.578798,    0.01772212],\n",
    "                  [0.13182636,  1.0197668,  -0.4468389],\n",
    "                  [0.45202246, -0.97592443,  0.7112372]], requires_grad = True),\n",
    "\n",
    "    torch.tensor([[-0.15909262, -1.7786636],\n",
    "                  [0.84765124,  0.24594283],\n",
    "                  [-0.13116787, -0.17851807]], requires_grad = True)\n",
    "\n",
    "]\n",
    "\n",
    "\n",
    "biases = [\n",
    "    torch.tensor([[-1.5699861,   1.2315004,   1.3946317,   1.1711024,   0.43351194]]\n",
    "                 ),\n",
    "    torch.tensor([[-0.75822645, -0.64358306, -0.6461524]]),\n",
    "    torch.tensor([[-0.5958931,   0.27386975]])\n",
    "]\n",
    "\n",
    "model = Network(5, weights, biases, 3, [2, 2, 3], 5, 100)\n",
    "model.startLearning(input, target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset and testing\n",
    "\n",
    "torch.manual_seed(87)\n",
    "\n",
    "from keras.datasets import mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "images = x_train[0:1000].reshape(1000,28*28) / 255\n",
    "labels = y_train[0:1000]\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5c7c5ccdbe53dd889b3175060589ae9f32fff2a14e800de73152da523e6a68d2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
